# Configuraci√≥n de logging
LOG_FILE="/app/logs/cron_$(date +%Y%m%d).log"
LOCK_FILE="/tmp/scraping_corrientes.lock"
ERROR_EMAIL="damian.diaz@vaovaodata.com"  

# Funci√≥n para logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Funci√≥n para limpiar al salir
cleanup() {
    if [ -f "$LOCK_FILE" ]; then
        rm -f "$LOCK_FILE"
        log "üßπ Lock file eliminado"
    fi
}

# Configurar trap para limpiar al salir
trap cleanup EXIT

# =============================================================================
# VERIFICAR QUE NO HAY OTRA INSTANCIA CORRIENDO
# =============================================================================
if [ -f "$LOCK_FILE" ]; then
    LOCK_PID=$(cat "$LOCK_FILE")
    if ps -p "$LOCK_PID" > /dev/null 2>&1; then
        log "‚ùå ERROR: Otra instancia ya est√° corriendo (PID: $LOCK_PID)"
        exit 1
    else
        log "‚ö†Ô∏è  Lock file obsoleto encontrado, eliminando..."
        rm -f "$LOCK_FILE"
    fi
fi

# Crear lock file
echo $$ > "$LOCK_FILE"
log "üîí Lock file creado (PID: $$)"

# =============================================================================
# PREPARAR ENTORNO
# =============================================================================
log "üöÄ Iniciando scraping diario de licitaciones de Corrientes"

# Cambiar al directorio del proyecto (ahora es la ra√≠z)
cd /app

# Verificar que el directorio existe
if [ ! -d "/app" ]; then
    log "‚ùå ERROR: Directorio /app no encontrado"
    exit 1
fi

# Verificar que main.py existe
if [ ! -f "main.py" ]; then
    log "‚ùå ERROR: main.py no encontrado en /app/corrientes"
    exit 1
fi

# =============================================================================
# CREAR BACKUP DE DATOS ANTERIORES 
# =============================================================================
BACKUP_DIR="/app/backups/$(date +%Y%m%d_%H%M%S)"
if [ -d "db" ] && [ "$(ls -A db)" ]; then
    log "üíæ Creando backup de datos anteriores en $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"
    cp -r db/* "$BACKUP_DIR/" 2>/dev/null || true
    cp -r docs/* "$BACKUP_DIR/" 2>/dev/null || true
    log "‚úÖ Backup completado"
fi

# =============================================================================
# EJECUTAR EL PIPELINE PRINCIPAL
# =============================================================================
log "‚öôÔ∏è  Ejecutando Main.py..."

# Ejecutar main.py y capturar el c√≥digo de salida
if python3 main.py; then
    EXIT_CODE=$?
    log "‚úÖ Pipeline ejecutado exitosamente (c√≥digo: $EXIT_CODE)"
    
    # Verificar que se crearon los archivos esperados
    if [ -f "db/runs.jsonl" ] && [ -f "db/pages.jsonl" ]; then
        TOTAL_PAGES=$(wc -l < db/pages.jsonl)
        TOTAL_HTML=$(find docs/pages_html -name "*.html" | wc -l)
        TOTAL_PNG=$(find docs/pages_png -name "*.png" | wc -l)
        
        log "üìä Resultados del scraping:"
        log "   - P√°ginas procesadas: $TOTAL_PAGES"
        log "   - Archivos HTML: $TOTAL_HTML"
        log "   - Archivos PNG: $TOTAL_PNG"
        
        # Verificar consistencia
        if [ "$TOTAL_PAGES" -eq "$TOTAL_HTML" ] && [ "$TOTAL_PAGES" -eq "$TOTAL_PNG" ]; then
            log "‚úÖ Datos consistentes - scraping completado correctamente"
        else
            log "‚ö†Ô∏è  ADVERTENCIA: Inconsistencia en los datos (p√°ginas: $TOTAL_PAGES, HTML: $TOTAL_HTML, PNG: $TOTAL_PNG)"
        fi
    else
        log "‚ùå ERROR: Archivos de salida no encontrados"
        exit 1
    fi
else
    EXIT_CODE=$?
    log "‚ùå ERROR: Pipeline fall√≥ con c√≥digo $EXIT_CODE"
    
    
    exit $EXIT_CODE
fi

# =============================================================================
# LIMPIAR ARCHIVOS ANTIGUOS 
# =============================================================================
log "üßπ Limpiando backups antiguos (>7 d√≠as)..."
find /app/backups -type d -mtime +7 -exec rm -rf {} + 2>/dev/null || true

# =============================================================================
# FINALIZAR
# =============================================================================
DURATION=$SECONDS
log "üèÅ Scraping completado en ${DURATION} segundos"
log "=================================================="

exit 0